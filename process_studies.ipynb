{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsFiPv5vG2c4VCZb0Naf9M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3f993b4fcae44f9b464637f7f1d0071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ffb8699e4214ba1ab976695aef05ac4",
              "IPY_MODEL_f4adfcafb80d487697d795292a33ec2d",
              "IPY_MODEL_ad1b5921e1764d66929a64d4abe20611"
            ],
            "layout": "IPY_MODEL_aaaed1aed264418599726c86ec37dd02"
          }
        },
        "8ffb8699e4214ba1ab976695aef05ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_effcaf4276c74dec8d6b7804e02729f6",
            "placeholder": "​",
            "style": "IPY_MODEL_83361b7f89bb4e45b5e8a92556b2c7d6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f4adfcafb80d487697d795292a33ec2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354f568559a6427e83fb3fd4939002d2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c8d358cc55145d8a1942245007e2067",
            "value": 2
          }
        },
        "ad1b5921e1764d66929a64d4abe20611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ccfa7633a834589a3072bb0736103bc",
            "placeholder": "​",
            "style": "IPY_MODEL_aeb360f71e5c478c8910d97486364c36",
            "value": " 2/2 [00:41&lt;00:00, 19.43s/it]"
          }
        },
        "aaaed1aed264418599726c86ec37dd02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effcaf4276c74dec8d6b7804e02729f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83361b7f89bb4e45b5e8a92556b2c7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "354f568559a6427e83fb3fd4939002d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8d358cc55145d8a1942245007e2067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ccfa7633a834589a3072bb0736103bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb360f71e5c478c8910d97486364c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-jk/ExData_Plotting1/blob/master/process_studies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook extracts and cleans text from PDF reports for use in training the buyer profile extractor model.**"
      ],
      "metadata": {
        "id": "h3140H82TCGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add input and output examples to jsonl file**"
      ],
      "metadata": {
        "id": "aSaUOBcBZMvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/alex-jk/buyers-ID-manual-project.git\n",
        "%cd buyers-ID-manual-project\n",
        "!ls"
      ],
      "metadata": {
        "id": "Gi3MKqB7cGcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1039cc79-afec-4855-98be-4615f69c15be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/buyers-ID-manual-project\n",
            "data\t\t     LICENSE\t\t    __pycache__\n",
            "extraction_utils.py  process_studies.ipynb  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# input_text = \"\"\"\n",
        "# Buyers were willing to travel significant distances to reach underage victims.\n",
        "# One man cited the Atlanta airport as a regular meeting place.\n",
        "# \"\"\"\n",
        "\n",
        "# output_text = \"\"\"\n",
        "# Buyers are often mobile and willing to travel, including to major hubs like the Atlanta airport.\n",
        "# \"\"\"\n",
        "\n",
        "# entry = {\"input\": input_text.strip(), \"output\": output_text.strip()}\n",
        "\n",
        "# with open(\"data/labeled_chunks.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
        "#     f.write(json.dumps(entry) + \"\\n\")"
      ],
      "metadata": {
        "id": "-l9bAG6lTEYW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "FHHdr7ZZTYe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install specific compatible versions for torch 2.3.1 / cu121\n",
        "!pip install torch==2.3.1+cu121 torchaudio==2.3.1+cu121 torchvision==0.18.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install the other pinned versions\n",
        "!pip install transformers==4.41.2 accelerate==0.31.0 --no-deps\n",
        "\n",
        "# Install compatible tokenizers version LAST to ensure it sticks\n",
        "!pip install tokenizers==0.19.1\n",
        "\n",
        "# Ensure base dependencies are present (redundant ok)\n",
        "!pip install bitsandbytes sentencepiece\n",
        "\n",
        "print(\"\\nInstalled specific package versions (including compatible tokenizers). PLEASE RESTART RUNTIME NOW.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTTOXwDwcuaQ",
        "outputId": "b28de71a-b4ca-401c-c868-2e54b1de0634"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==2.3.1+cu121 in /usr/local/lib/python3.11/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchaudio==2.3.1+cu121 in /usr/local/lib/python3.11/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.18.1+cu121 in /usr/local/lib/python3.11/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.1+cu121) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.1+cu121) (11.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1+cu121) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1+cu121) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.1+cu121) (1.3.0)\n",
            "Requirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.11/dist-packages (4.41.2)\n",
            "Requirement already satisfied: accelerate==0.31.0 in /usr/local/lib/python3.11/dist-packages (0.31.0)\n",
            "Requirement already satisfied: tokenizers==0.19.1 in /usr/local/lib/python3.11/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers==0.19.1) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2025.1.31)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "\n",
            "Installed specific package versions (including compatible tokenizers). PLEASE RESTART RUNTIME NOW.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "yCeel7fiPtID"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read input output file and write to jsonl**"
      ],
      "metadata": {
        "id": "YPvesEjPT4au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_output_df = pd.read_csv(\"data/buyers_id_manual_input_output.csv\")\n",
        "\n",
        "print(input_output_df.shape)\n",
        "print(input_output_df.columns)\n",
        "print(\"\\n-------------------------------\\n\")\n",
        "print(input_output_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u-YHG4rTcu7",
        "outputId": "8a83fee6-36b0-41d4-b91a-cdbea437d2a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 3)\n",
            "Index(['Study', 'Input', 'Output'], dtype='object')\n",
            "\n",
            "-------------------------------\n",
            "\n",
            "                                    Study  \\\n",
            "0  The Shapiro Group Georgia Demand Study   \n",
            "1  The Shapiro Group Georgia Demand Study   \n",
            "2  The Shapiro Group Georgia Demand Study   \n",
            "3  The Shapiro Group Georgia Demand Study   \n",
            "4  The Shapiro Group Georgia Demand Study   \n",
            "\n",
            "                                               Input  \\\n",
            "0  Almost half these men are the age 30-39, with ...   \n",
            "1  The data clearly debunk the myth that CSEC is ...   \n",
            "2  Not only are 65% of men who buy sex with young...   \n",
            "3  Craigslist is by far the most efficient medium...   \n",
            "4  While many of the men who exploit these childr...   \n",
            "\n",
            "                                              Output  \n",
            "0  Almost half these men are the age 30-39, with ...  \n",
            "1  Men who\\nrespond to advertisements for sex wit...  \n",
            "2  65% of men who buy sex with young females do s...  \n",
            "3  Buyers respond to Craigslist ads 3 times more ...  \n",
            "4  Nearly half of buyers are willing to pay for s...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_output_df = input_output_df.drop_duplicates(subset=[\"Study\", \"Input\", \"Output\"])\n",
        "\n",
        "# Convert to JSONL\n",
        "with open(\"data/labeled_chunks.jsonl\", \"w\") as f:\n",
        "    for _, row in input_output_df.iterrows():\n",
        "        json_obj = {\n",
        "            \"study\": row[\"Study\"],\n",
        "            \"input\": row[\"Input\"],\n",
        "            \"output\": row[\"Output\"]\n",
        "        }\n",
        "        f.write(json.dumps(json_obj) + \"\\n\")"
      ],
      "metadata": {
        "id": "jC56MIoNVPMZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Models for text extraction**"
      ],
      "metadata": {
        "id": "z7s-W-gNZPi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from extraction_utils import create_prompt_messages, extract_information\n",
        "\n",
        "print(\"Functions 'create_prompt_messages' and 'extract_information' imported successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRHpTCINVOxX",
        "outputId": "b086324b-cdc3-4401-d883-6184f0409d03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions 'create_prompt_messages' and 'extract_information' imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgJ0s70ynDtG",
        "outputId": "a752cd47-36ba-41a6-e4e0-d4529b605a55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "YYtd4ZYUZRw2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "# --- Load Model and Tokenizer ---\n",
        "# Load the model with 4-bit quantization to save memory (requires bitsandbytes)\n",
        "# Use device_map=\"auto\" to automatically use GPU if available\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\",         # Use GPU if available, otherwise CPU\n",
        "        torch_dtype=\"auto\",        # Automatically select appropriate dtype\n",
        "        trust_remote_code=True,    # Phi-3 requires this\n",
        "        # Optional: uncomment below for 4-bit loading (needs bitsandbytes)\n",
        "        # load_in_4bit=True,\n",
        "        # bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    print(f\"Model '{model_id}' loaded successfully.\")\n",
        "\n",
        "    # --- Create a Hugging Face Pipeline for easier text generation ---\n",
        "    # Note: max_new_tokens controls how long the generated output can be. Adjust as needed.\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        # Adjust max_new_tokens if your extracted text might be longer\n",
        "        # Needs to be long enough for the longest expected extraction + \"NONE\"\n",
        "        max_new_tokens=256,\n",
        "        # Temperature=0 means more deterministic output, higher means more creative/random\n",
        "        # temperature=0.0,\n",
        "        # top_p=0.95, # Optional: nucleus sampling\n",
        "        do_sample=False # Set to False for more deterministic extraction\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model or creating pipeline: {e}\")\n",
        "    print(\"Ensure you have sufficient RAM/VRAM and necessary libraries installed.\")\n",
        "    print(\"Consider using Google Colab with a T4 GPU runtime.\")\n",
        "    # Exit if model loading fails\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "d3f993b4fcae44f9b464637f7f1d0071",
            "8ffb8699e4214ba1ab976695aef05ac4",
            "f4adfcafb80d487697d795292a33ec2d",
            "ad1b5921e1764d66929a64d4abe20611",
            "aaaed1aed264418599726c86ec37dd02",
            "effcaf4276c74dec8d6b7804e02729f6",
            "83361b7f89bb4e45b5e8a92556b2c7d6",
            "354f568559a6427e83fb3fd4939002d2",
            "6c8d358cc55145d8a1942245007e2067",
            "9ccfa7633a834589a3072bb0736103bc",
            "aeb360f71e5c478c8910d97486364c36"
          ]
        },
        "id": "86Z4-8tTnLC_",
        "outputId": "4569c7de-cb6d-4c9a-f999-52ad7f4a3332"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3f993b4fcae44f9b464637f7f1d0071"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'microsoft/Phi-3-mini-4k-instruct' loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example Usage**"
      ],
      "metadata": {
        "id": "XywDoaLuZcBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text_1 = \"Almost half these men are the age 30-39, with the next largest group being men under age 30. The mean age is 33 and the median 31. The youngest survey participant was 18, and the oldest was 67.\"\n",
        "\n",
        "input_text_2 = \"The data clearly debunk the myth that CSEC is a problem relegated to the urban core. Men who respond to advertisements for sex with young females come from all over metro Atlanta, the geographic market where the advertisements in this study were targeted.\"\n",
        "\n",
        "input_text_3 = \"This paragraph discusses unrelated economic factors in the region and contains no information about buyers or traffickers.\"\n",
        "\n",
        "input_text_4 = \"Research indicates traffickers often groom potential buyers by displaying luxury goods online and frequenting specific forums known for risky behavior discussions. Victims may appear withdrawn or display signs of coaching. Reporting suspicions anonymously through the national hotline is encouraged.\""
      ],
      "metadata": {
        "id": "uVOQqRnEZeOg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Extracting Information ---\")\n",
        "\n",
        "# Check if the pipeline object exists before trying to use it\n",
        "if 'pipe' in locals() and pipe is not None:\n",
        "    print(f\"\\nInput 1:\\n{input_text_1}\")\n",
        "    extraction_1 = extract_information(input_text_1, pipe)\n",
        "    print(f\"\\nExtraction 1:\\n{extraction_1}\")\n",
        "\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    print(f\"\\nInput 2:\\n{input_text_2}\")\n",
        "    extraction_2 = extract_information(input_text_2, pipe)\n",
        "    print(f\"\\nExtraction 2:\\n{extraction_2}\")\n",
        "\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    print(f\"\\nInput 3:\\n{input_text_3}\")\n",
        "    extraction_3 = extract_information(input_text_3, pipe)\n",
        "    print(f\"\\nExtraction 3:\\n{extraction_3}\")\n",
        "\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    print(f\"\\nInput 4:\\n{input_text_4}\")\n",
        "    extraction_4 = extract_information(input_text_4, pipe)\n",
        "    print(f\"\\nExtraction 4:\\n{extraction_4}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nERROR: The 'pipe' object (text generation pipeline) was not found or not created successfully.\")\n",
        "    print(\"Please ensure the model loading cell was run successfully after importing functions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju44xbqscRuN",
        "outputId": "7536ed1c-3072-44d2-d044-804d878ebe5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extracting Information ---\n",
            "\n",
            "Input 1:\n",
            "Almost half these men are the age 30-39, with the next largest group being men under age 30. The mean age is 33 and the median 31. The youngest survey participant was 18, and the oldest was 67.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extraction 1:\n",
            "Almost half these men are the age 30-39, with the next largest group being men under age 30. The mean age is 33 and the median 31. The youngest survey participant was 18, and the oldest was 67.\n",
            "--------------------\n",
            "\n",
            "Input 2:\n",
            "The data clearly debunk the myth that CSEC is a problem relegated to the urban core. Men who respond to advertisements for sex with young females come from all over metro Atlanta, the geographic market where the advertisements in this study were targeted.\n",
            "\n",
            "Extraction 2:\n",
            "Men who respond to advertisements for sex with young females come from all over metro Atlanta.\n",
            "--------------------\n",
            "\n",
            "Input 3:\n",
            "This paragraph discusses unrelated economic factors in the region and contains no information about buyers or traffickers.\n",
            "\n",
            "Extraction 3:\n",
            "NONE\n",
            "--------------------\n",
            "\n",
            "Input 4:\n",
            "Research indicates traffickers often groom potential buyers by displaying luxury goods online and frequenting specific forums known for risky behavior discussions. Victims may appear withdrawn or display signs of coaching. Reporting suspicions anonymously through the national hotline is encouraged.\n",
            "\n",
            "Extraction 4:\n",
            "Traffickers often groom potential buyers by displaying luxury goods online and frequenting specific forums known for risky behavior discussions. Victims may appear withdrawn or display signs of coaching. Reporting suspicions anonymously through the national hotline is encouraged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check installed versions of required packages\n",
        "!pip list | grep -E 'transformers|torch|accelerate|flash-attn'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMiPjqyUfUK8",
        "outputId": "e673c17f-42e0-462e-afd9-7c39cd4ec69f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate                            0.31.0\n",
            "sentence-transformers                 3.4.1\n",
            "torch                                 2.3.1+cu121\n",
            "torchaudio                            2.3.1+cu121\n",
            "torchsummary                          1.5.1\n",
            "torchvision                           0.18.1+cu121\n",
            "transformers                          4.41.2\n"
          ]
        }
      ]
    }
  ]
}